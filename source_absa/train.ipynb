{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing Predictor\n",
      "Loading model model/en-laptops-absa\n",
      "Config loaded from model/en-laptops-absa/config.json\n",
      "Aspects loaded from model/en-laptops-absa/aspects.jsonl\n",
      "Config loaded from model/en-laptops-absa/config.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import spacy\n",
    "\n",
    "import utils.dataloader as dl\n",
    "\n",
    "from absa import Predictor\n",
    "from security import Authorization\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "pred = Predictor(os.path.join('model', 'en-laptops-absa'))\n",
    "key = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJleHAiOjE2MTk1OTU3MDYsInN1YiI6IkFsZXhhbmRlciBSaWV0emxlciIsImlzcyI6ImRlZXBvcGluaW9uLmFpIiwibGFuZ3VhZ2VzIjpbIioiXSwiZnVuY3Rpb25hbGl0eSI6WyIqLyoiXSwiaWF0IjoxNTg4MDU5NzA2fQ.Qz5VPxBIWmmUUpNUp29jw1IKL8TYS_I0vrP_LRWZ9v09tueKHvSddoa8lwjFGi6plAtt6j0w6RiCnSAiw5djQJBXaY40TL36OFjddRrS97zstyizLrXKigQZRqN0w9j53OTV9ViJSXZ8itPLs7bt0KkTsFxoO7gqzC6--SR63c50KS4JQNXCm0an6bePGAtL6OtYABCeLp-TQaR4BfMsqvbBS5T3NSOx65ZPc5COXHZdzRN3gpdc-FXwzRmhzk8LcP4O4tZhxqHUD4u5Rx6sHiCKXULsS_-_hg4344_6taK3UX5IM5h50uXWdLtZ8d-otpZMM0sZijy9XT4jz-mBd_Xzg8nOcHz-8CZXra6NBNgBxpZkJTU_MekZwXKoNE7ktEd5xMruqaut0E_nXXeh32okbuqJ6fmb5F6VQzHBK5Z9Y9WU79tDs5NK9q_zFhLh7ldJKBusCQrB8ADzDs_eBTXaxfMhi0pbFFZWrzIfDce3vrEdyQEXqo8vkrxTzR1YDg7aV47md_L309PolwVM66C6KmnKOT-FVCdIspW96iXoBJ8y7nAkYEM41u5xjqvK39qfmfqA5QeVQXUvBoU9XU0CH1pU6rmnsIpIFphBl598qqIynWWOfdaIk6CRTo-CTzPk06JY8XIuuBayJcbN26MAMKtyeAy7KMfXWmIY3DY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train absa laptop Model on Aspects for Sem-Eval Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train Model:\n",
    "    have Aspect file\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../SemEval-2015-ABSA/absa_15_laptops_train_data.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, aspect_category_sentiments, (idx2aspectlabel, idx2sentilabel), cats = dl.semeval_to_aspectsentiment_hr(filename)\n",
    "len(cats)\n",
    "\n",
    "model_folder = os.path.join('model', 'en-laptops-absa')\n",
    "documents = sentences\n",
    "target = 'model/en-laptops-absa_bs32_ep20_nlw0.5_lr2e-5'\n",
    "aspects = cats\n",
    "token = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_folder, documents, aspects, target, token,\n",
    "          batchsize=32, encrypt=True, state_callback=None,\n",
    "          stop_callback=None, epochs=20, validation_documents=None, seed=None,\n",
    "          none_label_weight=0.5, learning_rate=2e-5, save_interval=None):\n",
    "    \"\"\"Trains a model with given annotated documents.\n",
    "    Args:\n",
    "        model_folder (str): A path or name of the base model that should be used.\n",
    "        documents (list): An annotated list of documents.\n",
    "        validation_documents (list): An annotated list of documents.\n",
    "        target: (string): A path where the model should be saved.\n",
    "        token (string): A JSON web token which is validated.\n",
    "        batchsize (int): The batchsize used for training.\n",
    "        epochs (int): The maximum number of epochs for training.\n",
    "        encrypt (boolean): A flag whether to encrypt the model or not, default *True*.\n",
    "        save_interval (int): Number of global steps after which a model checkpoint is saved.\n",
    "        state_callback: Callback that is executed regularly and gives progress and score params back.\n",
    "   \"\"\"\n",
    "    # Authorize and Check\n",
    "    authorization_response = Authorization.authorize(token, functionality='absa/train')\n",
    "    if not authorization_response['verified']:\n",
    "        raise ValueError(authorization_response['message'])\n",
    "    model_folder = get_model_dir(model_folder, token=token)\n",
    "    # Preconditions\n",
    "    if seed is not None:\n",
    "        fix_seed(seed)\n",
    "    # Load and Train Model\n",
    "    handlers = [Decrypter(), ShuffleData(),\n",
    "                Train(), TorchOptimizer(optclass=Ranger, lr=learning_rate),\n",
    "                LearningRateReporterAndChanger(),\n",
    "                Encrypter(encrypt)]\n",
    "    if batchsize is None:\n",
    "        handlers.append(AutoBatchsizeSelector(basemodel='bert-base-uncased', maxbatchsize=batchsize, verbose=True))\n",
    "    if stop_callback is not None:\n",
    "        handlers.append(CustomTrainingStopper(stop_training_callback=stop_callback))\n",
    "    if state_callback is not None:\n",
    "        handlers.append(ProgressReporter(reporter=state_callback))\n",
    "    X, Y = get_text_aspect_pairs(documents=documents, labels=DEFAULT_SENTIMENT_LABELS,\n",
    "                                 none_label_weight=none_label_weight)\n",
    "    dataset_size = len(X)\n",
    "    if validation_documents is not None and state_callback is not None:\n",
    "        X_test, Y_test = get_text_aspect_pairs(documents=validation_documents, labels=DEFAULT_SENTIMENT_LABELS)\n",
    "\n",
    "        # Custom evaluator for classification framework\n",
    "        def evaluator(Y_true, Y_pred):\n",
    "            return Metrics().calc_score_absa(X=X_test, Y_true=Y_true, Y_pred=Y_pred, labels=DEFAULT_SENTIMENT_LABELS,\n",
    "                                             aspects=aspects\n",
    "                                             )\n",
    "\n",
    "        handlers.append(ScoreReporter(reporter=state_callback, evaluator=evaluator, X=X_test, Y=Y_test))\n",
    "        BestModelKeeper(metricname='val_loss', maximize=False, verbose=True)\n",
    "        handlers.append(\n",
    "            EarlyStopping(patience=dataset_size * 2, lr_reduction_patience=dataset_size, lr_reduction_factor=0.1,\n",
    "                          metricname='val_loss', verbose=True, epsilon=0.0001, maximize=False))\n",
    "\n",
    "    ch = CallbackHandler(handlers)\n",
    "    absa = Classifier(model=model_folder, num_labels=len(DEFAULT_SENTIMENT_LABELS), device=get_device(), ch=ch)\n",
    "    absa.model.config.__dict__['do_aspects'] = aspects\n",
    "    absa.model.config.__dict__['id2label'] = {id: label for id, label in enumerate(DEFAULT_SENTIMENT_LABELS)}\n",
    "    absa.model.config.__dict__['label2id'] = {label: id for id, label in enumerate(DEFAULT_SENTIMENT_LABELS)}\n",
    "    absa.model.train()\n",
    "    absa(X, Y, batchsize=batchsize, verbose=True, epochs=epochs)\n",
    "    # Save Model and Aspects\n",
    "    absa.save(target)\n",
    "    # Save to config\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
