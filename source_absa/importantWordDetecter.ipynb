{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Word Detection\n",
    "\n",
    "1. Load Dataset and pick 60 Documents for now\n",
    "2. Do sentence splitting\n",
    "3. Leave One Out (LOO)\n",
    "\n",
    "4. Find important Word through Prediciton\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import utils.text_processing as tp\n",
    "import utils.dataloader as dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and pick first 60 examples for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'SemEval_2015_laptops/absa_15_laptops_train_data.xml'\n",
    "filename = 'SemEval_2015_laptops/test_data.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences, aspect_category_sentiments, (idx2aspectlabel, idx2sentilabel), cats = dl.semeval_to_aspectsentiment_hr(filename)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sentence Splitting\n",
    "- have list with splitted sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Leave One Out (LOO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of Lists of tokenized sentences\n",
    "tok_sentences = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    tok_sentences.append(sentence.split(' '))\n",
    "\n",
    "len(tok_sentences)\n",
    "# print(tok_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go over the list of tokens in a sentence\n",
    "# and drop each word after the other\n",
    "# go over sentences in list of tokenized sentences\n",
    "sentence_packages = []\n",
    "for sent in range(len(tok_sentences)):\n",
    "    original_sentence = tp.detokenize(tok_sentences[sent])\n",
    "    modified_sentences = []\n",
    "# go over token in sentence\n",
    "    for token in range(len(tok_sentences[sent])):\n",
    "        tok_mod_sentence = tp.get_token_dropped_sentence_at_pos(tok_sentences[sent], token)\n",
    "        modified_sentences.append((tok_sentences[sent][token], tp.detokenize(tok_mod_sentence)))\n",
    "    sentence_packages.append(\n",
    "        {\n",
    "            'original_sentence':original_sentence,\n",
    "            'modified_sentences':modified_sentences\n",
    "        }        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'original_sentence': 'hours battery. than of 10 got more', 'modified_sentences': ('than', 'hours battery. of 10 got more')}, {'original_sentence': 'super really graphics a processor card. fast and nice', 'modified_sentences': ('processor', 'super really graphics a card. fast and nice')}]\n"
     ]
    }
   ],
   "source": [
    "print(sentence_packages[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence_packages),len(aspect_category_sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LAPTOP#OPERATION_PERFORMANCE': 'POS'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect_category_sentiments[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict with BERT for ABSA Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing Predictor\n",
      "Loading model models/en-laptops-absa\n",
      "Config loaded from models/en-laptops-absa/config.json\n",
      "Aspects loaded from models/en-laptops-absa/aspects.jsonl\n",
      "Config loaded from models/en-laptops-absa/config.json\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import spacy\n",
    "import numpy as np\n",
    "import transformers\n",
    "import pandas as pd\n",
    "\n",
    "from absa import Predictor\n",
    "from security import Authorization\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "pred = Predictor(os.path.join('models','en-laptops-absa'))\n",
    "\n",
    "key = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJleHAiOjE2MTk1OTU3MDYsInN1YiI6IkFsZXhhbmRlciBSaWV0emxlciIsImlzcyI6ImRlZXBvcGluaW9uLmFpIiwibGFuZ3VhZ2VzIjpbIioiXSwiZnVuY3Rpb25hbGl0eSI6WyIqLyoiXSwiaWF0IjoxNTg4MDU5NzA2fQ.Qz5VPxBIWmmUUpNUp29jw1IKL8TYS_I0vrP_LRWZ9v09tueKHvSddoa8lwjFGi6plAtt6j0w6RiCnSAiw5djQJBXaY40TL36OFjddRrS97zstyizLrXKigQZRqN0w9j53OTV9ViJSXZ8itPLs7bt0KkTsFxoO7gqzC6--SR63c50KS4JQNXCm0an6bePGAtL6OtYABCeLp-TQaR4BfMsqvbBS5T3NSOx65ZPc5COXHZdzRN3gpdc-FXwzRmhzk8LcP4O4tZhxqHUD4u5Rx6sHiCKXULsS_-_hg4344_6taK3UX5IM5h50uXWdLtZ8d-otpZMM0sZijy9XT4jz-mBd_Xzg8nOcHz-8CZXra6NBNgBxpZkJTU_MekZwXKoNE7ktEd5xMruqaut0E_nXXeh32okbuqJ6fmb5F6VQzHBK5Z9Y9WU79tDs5NK9q_zFhLh7ldJKBusCQrB8ADzDs_eBTXaxfMhi0pbFFZWrzIfDce3vrEdyQEXqo8vkrxTzR1YDg7aV47md_L309PolwVM66C6KmnKOT-FVCdIspW96iXoBJ8y7nAkYEM41u5xjqvK39qfmfqA5QeVQXUvBoU9XU0CH1pU6rmnsIpIFphBl598qqIynWWOfdaIk6CRTo-CTzPk06JY8XIuuBayJcbN26MAMKtyeAy7KMfXWmIY3DY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function iterates all packages and evaluates all sentence variations.\n",
    "For each package (=original sentence) we find the important_words that will change the result.\n",
    "Expected output:\n",
    "[['word1', 'word2'],['word3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICE=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction of the original sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for package in sentence_packages:\n",
    "    document = {'text': package['original_sentence'], 'segments':[{'span':[0,0],'text': package['original_sentence']}]}\n",
    "    documents.append(document)\n",
    "    \n",
    "results = pred.predict(documents, key, with_segments=True)\n",
    "\n",
    "original_results = []\n",
    "for result in results:\n",
    "    original_results.append(result[0])\n",
    "#print('original_results: ', original_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'This computer is absolutely amazing.',\n",
       " 'span': [0, 0],\n",
       " 'aspect_sentiments': [{'aspect': 'Laptop (general)', 'sentiment': 'POS'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction of modified sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "10\n",
      "[1, 1, 1, 1, 1, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "# create list with indices where every sentence from one package has the same index\n",
    "# e.g. indices = [1,1,1,1,2,2,2,2,3,3,4,4,4,4,4,4,4]\n",
    "# this would be the indices for 4 sentences\n",
    "\n",
    "# this is done to predict all modified sentences in one run \n",
    "# and be able to map them together accordingly afterwards.\n",
    "\n",
    "package_indices = []\n",
    "package_index = 0\n",
    "for package in sentence_packages:\n",
    "    package_index += 1\n",
    "    for mod_sent in package['modified_sentences']:\n",
    "        package_indices.append(package_index)\n",
    "        \n",
    "print(len(package_indices))\n",
    "print(package_index)\n",
    "print(package_indices[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified_results_unmapped:  109\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "documents = []\n",
    "package_indices = []\n",
    "package_index = 0\n",
    "for package in sentence_packages:\n",
    "    package_index += 1\n",
    "    for mod_set in package['modified_sentences']:  \n",
    "        package_indices.append(package_index)\n",
    "        sentence = mod_set[1]\n",
    "        document = {'text': sentence, 'segments':[{'span':[0,0],'text': sentence}]}\n",
    "        documents.append(document)\n",
    "    \n",
    "results = pred.predict(documents, key, with_segments=True)\n",
    "\n",
    "\n",
    "\n",
    "modified_results_unmapped = []\n",
    "for result in results:\n",
    "    modified_results_unmapped.append(result[0])\n",
    "print('modified_results_unmapped: ', len(modified_results_unmapped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[[{'text': 'computer is absolutely amazing.', 'span': [0, 0], 'aspect_sentiments': [{'aspect': 'Laptop (general)', 'sentiment': 'POS'}]}, {'text': 'This is absolutely amazing.', 'span': [0, 0], 'aspect_sentiments': [{'aspect': 'Laptop (general)', 'sentiment': 'POS'}]}, {'text': 'This computer absolutely amazing.', 'span': [0, 0], 'aspect_sentiments': [{'aspect': 'Laptop (general)', 'sentiment': 'POS'}]}, {'text': 'This computer is amazing.', 'span': [0, 0], 'aspect_sentiments': [{'aspect': 'Laptop (general)', 'sentiment': 'POS'}]}, {'text': 'This computer is absolutely', 'span': [0, 0], 'aspect_sentiments': [{'aspect': 'Laptop (general)', 'sentiment': 'POS'}]}]]\n"
     ]
    }
   ],
   "source": [
    "# this is the mapping of the modified results, as described before\n",
    "\n",
    "modified_results = []\n",
    "modified_sentence = []\n",
    "check = 1\n",
    "for e, result in enumerate(modified_results_unmapped):\n",
    "    i = package_indices[e]    \n",
    "    if i == check:\n",
    "        modified_sentence.append(result)\n",
    "    else:\n",
    "        modified_results.append(modified_sentence)\n",
    "        modified_sentence = []\n",
    "        modified_sentence.append(result)\n",
    "    check = i\n",
    "modified_results.append(modified_sentence)\n",
    "print(len(modified_results))\n",
    "print(modified_results[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison of the results\n",
    "# we need: \n",
    "# original_results['aspect_sentiments']\n",
    "# for results in modified_results['aspect_sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare modified with original\n",
    "# if they are the same, drop the modified sentence\n",
    "# if something is different, append the modified sentence to the database ready to be attacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'This computer is absolutely amazing.', 'span': [0, 0], 'aspect_sentiments': [{'aspect': 'Laptop (general)', 'sentiment': 'POS'}]}, {'text': 'got more than 10 hours of battery.', 'span': [0, 0], 'aspect_sentiments': [{'aspect': 'Battery', 'sentiment': 'POS'}]}, {'text': 'a super fast processor and a really nice graphics card.', 'span': [0, 0], 'aspect_sentiments': [{'aspect': 'Graphics', 'sentiment': 'POS'}, {'aspect': 'CPU', 'sentiment': 'POS'}, {'aspect': 'Performance', 'sentiment': 'POS'}]}, {'text': 'Also plenty of storage with 250 GB ram.', 'span': [0, 0], 'aspect_sentiments': [{'aspect': 'Memory', 'sentiment': 'POS'}, {'aspect': 'Storage', 'sentiment': 'POS'}]}, {'text': \"I'm shocked as to how easy it is to get used to.\", 'span': [0, 0], 'aspect_sentiments': []}, {'text': \"I've only had mine a day but I'm already used to it.\", 'span': [0, 0], 'aspect_sentiments': []}, {'text': 'GET THIS COMPUTER FOR PORTABILITY AND FAST PROCESSING!', 'span': [0, 0], 'aspect_sentiments': [{'aspect': 'Portability', 'sentiment': 'POS'}, {'aspect': 'Performance', 'sentiment': 'POS'}]}, {'text': 'the laptop was really good and it goes really fast just the way i thought it would run.', 'span': [0, 0], 'aspect_sentiments': [{'aspect': 'Laptop (general)', 'sentiment': 'POS'}, {'aspect': 'Performance', 'sentiment': 'POS'}]}, {'text': 'i would really recommend it to any person out there to get this laptop because its really worth it.', 'span': [0, 0], 'aspect_sentiments': [{'aspect': 'Laptop (general)', 'sentiment': 'POS'}, {'aspect': 'Price', 'sentiment': 'POS'}]}, {'text': 'And its really cheap and you wont regret buying it.', 'span': [0, 0], 'aspect_sentiments': [{'aspect': 'Laptop (general)', 'sentiment': 'POS'}, {'aspect': 'Price', 'sentiment': 'POS'}]}]\n"
     ]
    }
   ],
   "source": [
    "print(original_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[{'original_sentence': 'got more than 10 hours of battery.', 'original_result': [{'aspect': 'Battery', 'sentiment': 'POS'}], 'modified_sentences': [['got more 10 hours of battery.']], 'modified_results': [[[{'aspect': 'Battery', 'sentiment': 'NEU'}]]]}, {'original_sentence': 'a super fast processor and a really nice graphics card.', 'original_result': [{'aspect': 'Graphics', 'sentiment': 'POS'}, {'aspect': 'CPU', 'sentiment': 'POS'}, {'aspect': 'Performance', 'sentiment': 'POS'}], 'modified_sentences': [['a super processor and a really nice graphics card.', 'a super fast and a really nice graphics card.']], 'modified_results': [[[{'aspect': 'Graphics', 'sentiment': 'POS'}, {'aspect': 'CPU', 'sentiment': 'POS'}], [{'aspect': 'Graphics', 'sentiment': 'POS'}, {'aspect': 'Performance', 'sentiment': 'POS'}]]]}]\n"
     ]
    }
   ],
   "source": [
    "loo_results = []\n",
    "\n",
    "c = 0   \n",
    "\n",
    "for e, modified_result_set in enumerate(modified_results):\n",
    "    successfull_modifications_set_txt = []\n",
    "    successfull_modifications_set_aspsent = []\n",
    "    original_result = original_results[e]\n",
    "    o_aspect_sentiment = original_result['aspect_sentiments']\n",
    "    \n",
    "    successfull_modifications_txt = []\n",
    "    successfull_modifications_aspsent = []\n",
    "    for modified_result in modified_result_set:\n",
    "        m_aspect_sentiment = modified_result['aspect_sentiments']\n",
    "        \n",
    "        if o_aspect_sentiment != m_aspect_sentiment:\n",
    "            # print('original_result :', original_result, 'modified_result: ', modified_result)\n",
    "            successfull_modifications_txt.append(modified_result['text'])\n",
    "            successfull_modifications_aspsent.append(modified_result['aspect_sentiments'])\n",
    "    successfull_modifications_set_txt.append(successfull_modifications_txt)\n",
    "    successfull_modifications_set_aspsent.append(successfull_modifications_aspsent)\n",
    "    \n",
    "    if successfull_modifications_txt:\n",
    "        loo_results.append(\n",
    "            {\n",
    "                'original_sentence': original_result['text'],\n",
    "                'original_result': original_result['aspect_sentiments'],\n",
    "                'modified_sentences': successfull_modifications_set_txt,\n",
    "                'modified_results': successfull_modifications_set_aspsent\n",
    "            })\n",
    "        \n",
    "#print(c)   \n",
    "print(len(loo_results))\n",
    "print(loo_results[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'This'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "o_sent = 'This computer is Amazing'.split(' ')\n",
    "m_sent = 'computer is Amazing'.split()\n",
    "\n",
    "#o_set = set(o_sent)\n",
    "\n",
    "word = set(o_sent).difference(set(m_sent))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_sentences = []\n",
    "for sentence in sentences:\n",
    "    tok_sentences.append(sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'original_sentence': 'got more than 10 hours of battery.', 'modified_sentences': [('than', 'got more 10 hours of battery.')]}, {'original_sentence': 'a super fast processor and a really nice graphics card.', 'modified_sentences': [('fast', 'a super processor and a really nice graphics card.'), ('processor', 'a super fast and a really nice graphics card.')]}, {'original_sentence': 'Also plenty of storage with 250 GB ram.', 'modified_sentences': [('plenty', 'Also of storage with 250 GB ram.'), ('ram.', 'Also plenty of storage with 250 GB')]}, {'original_sentence': \"I'm shocked as to how easy it is to get used to.\", 'modified_sentences': [('used', \"I'm shocked as to how easy it is to get to.\"), ('to.', \"I'm shocked as to how easy it is to get used\")]}, {'original_sentence': 'GET THIS COMPUTER FOR PORTABILITY AND FAST PROCESSING!', 'modified_sentences': [('PORTABILITY', 'GET THIS COMPUTER FOR AND FAST PROCESSING!'), ('FAST', 'GET THIS COMPUTER FOR PORTABILITY AND PROCESSING!'), ('PROCESSING!', 'GET THIS COMPUTER FOR PORTABILITY AND FAST')]}, {'original_sentence': 'the laptop was really good and it goes really fast just the way i thought it would run.', 'modified_sentences': [('fast', 'the laptop was really good and it goes really just the way i thought it would run.')]}, {'original_sentence': 'i would really recommend it to any person out there to get this laptop because its really worth it.', 'modified_sentences': [('worth', 'i would really recommend it to any person out there to get this laptop because its really it.')]}, {'original_sentence': 'And its really cheap and you wont regret buying it.', 'modified_sentences': [('cheap', 'And its really and you wont regret buying it.'), ('wont', 'And its really cheap and you regret buying it.'), ('regret', 'And its really cheap and you wont buying it.')]}]\n"
     ]
    }
   ],
   "source": [
    "sentence_packages = []\n",
    "for item in loo_results:\n",
    "    o_sent = item['original_sentence'].split(' ')\n",
    "    \n",
    "    for lst in item['modified_sentences']:\n",
    "        modified_sentences = []\n",
    "        for sentence in lst:\n",
    "            m_sent = sentence.split()\n",
    "            for word in set(o_sent).difference(set(m_sent)):\n",
    "                word = word\n",
    "            \n",
    "                modified_sentences.append((word, tp.detokenize(m_sent)))\n",
    "    sentence_packages.append(\n",
    "    {\n",
    "        'original_sentence': tp.detokenize(o_sent),\n",
    "        'modified_sentences': modified_sentences\n",
    "    })\n",
    "    \n",
    "print(sentence_packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in range(len(tok_sentences[sent])):\n",
    "        tok_mod_sentence = tp.get_token_dropped_sentence_at_pos(tok_sentences[sent], token)\n",
    "        modified_sentences.append((tok_sentences[sent][token], tp.detokenize(tok_mod_sentence)))\n",
    "    sentence_packages.append(\n",
    "        {\n",
    "            'original_sentence':original_sentence,\n",
    "            'modified_sentences':modified_sentences\n",
    "        }        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'first': {'aspect': 'Price', 'sentiment': 'POS'}, 'second': None}, {'first': {'aspect': 'Laptop (general)', 'sentiment': 'POS'}, 'second': {'aspect': 'Laptop (general)', 'sentiment': 'NEG'}}]\n"
     ]
    }
   ],
   "source": [
    "# list difference example\n",
    "aspect_sentiments =  [{\n",
    "\t\t\t'aspect': 'Laptop (general)',\n",
    "\t\t\t'sentiment': 'NEG'\n",
    "\t\t}, {\n",
    "\t\t\t'aspect': 'Price',\n",
    "\t\t\t'sentiment': 'POS'\n",
    "\t\t}]\n",
    "aspect_sentiments2 = [{\n",
    "\t\t\t'aspect': 'Laptop (general)',\n",
    "\t\t\t'sentiment': 'POS'\n",
    "\t\t}]\n",
    "\n",
    "def sym_compare_aspect_list(aspects, aspects2):\n",
    "    diff_first_second = compare_aspect_list(aspects, aspects2)\n",
    "    diff_second_first = compare_aspect_list(aspects2, aspects, only_missing=True)\n",
    "  \n",
    "    return diff_first_second + diff_second_first\n",
    "    \n",
    "    \n",
    "def compare_aspect_list(aspects, aspects2, only_missing=False):\n",
    "    '''\n",
    "    check if aspects2 contains all elements from aspects\n",
    "    compare if sentiments are identical\n",
    "    returns list with differences\n",
    "    '''\n",
    "    diff = []\n",
    "    for aspect in aspects:\n",
    "        found = False\n",
    "        for aspect2 in aspects2:\n",
    "            if aspect['aspect'] == aspect2['aspect']:\n",
    "                found = True\n",
    "                if aspect['sentiment'] == aspect2['sentiment']:\n",
    "                    continue # same\n",
    "                else:\n",
    "                    if only_missing:\n",
    "                        diff.append({'first': aspect, 'second': aspect2})\n",
    "\n",
    "        if not found:\n",
    "            diff.append({'first': aspect, 'second': None})\n",
    "    return diff\n",
    "\n",
    "                \n",
    "print(sym_compare_aspect_list(aspect_sentiments, aspect_sentiments2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'original_result_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-585fc8af48ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moriginal_result_sets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moriginal_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0moriginal_result\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moriginal_result_sets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtexts_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_result_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0maspects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msentiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'original_result_set' is not defined"
     ]
    }
   ],
   "source": [
    "texts_list = []\n",
    "aspects_list = []\n",
    "sentiments_list = []\n",
    "\n",
    "for original_result_sets in original_results:\n",
    "    for original_result in original_result_sets:\n",
    "        texts_list.append(original_result_set['text'])\n",
    "        aspects = []\n",
    "        sentiments = []\n",
    "        for aspect_sentiment in original_result_set['aspect_sentiments']:\n",
    "            aspects.append(aspect_sentiment['aspect'])\n",
    "            sentiments.append(aspect_sentiment['sentiment'])\n",
    "        aspects_list.append(aspects)\n",
    "        sentiments_list.append(sentiments)\n",
    "\n",
    "print(len(texts_list), texts_list)\n",
    "print(len(aspects_list), aspects_list)\n",
    "print(len(sentiments_list), sentiments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This computer is absolutely amazing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got more than 10 hours of battery.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a super fast processor and a really nice graphics card.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Also plenty of storage with 250 GB ram.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET THIS COMPUTER FOR PORTABILITY AND FAST PROCESSING!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the laptop was really good and it goes really fast just the way i thought it would run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i would really recommend it to any person out there to get this laptop because its really worth it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And its really cheap and you wont regret buying it.\n"
     ]
    }
   ],
   "source": [
    "for original_result_set in original_result_sets:\n",
    "    \n",
    "    if original_result_set[0]:\n",
    "        original_result = original_result_set[0][0]\n",
    "        #original_aspect = original_result['aspect']\n",
    "        #original_sentiment = original_result['sentiment']\n",
    "        \n",
    "    else:\n",
    "        print(original_result_set)\n",
    "        sentence_packages.remove(package)\n",
    "        print(package)\n",
    "        \n",
    "    original_results.append(original_result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'And its really cheap and you wont regret buying it.', 'span': [0, 0], 'aspect_sentiments': [{'aspect': 'Laptop (general)', 'sentiment': 'POS'}, {'aspect': 'Price', 'sentiment': 'POS'}]}\n"
     ]
    }
   ],
   "source": [
    "print(original_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This computer is absolutely amazing.\n",
      "got more than 10 hours of battery.\n",
      "a super fast processor and a really nice graphics card.\n",
      "Also plenty of storage with 250 GB ram.\n",
      "GET THIS COMPUTER FOR PORTABILITY AND FAST PROCESSING!\n",
      "the laptop was really good and it goes really fast just the way i thought it would run.\n",
      "i would really recommend it to any person out there to get this laptop because its really worth it.\n",
      "And its really cheap and you wont regret buying it.\n"
     ]
    }
   ],
   "source": [
    "for item in sentence_packages:\n",
    "    print(item['original_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This computer is absolutely amazing.\n",
      "got more than 10 hours of battery.\n",
      "a super fast processor and a really nice graphics card.\n",
      "Also plenty of storage with 250 GB ram.\n",
      "GET THIS COMPUTER FOR PORTABILITY AND FAST PROCESSING!\n",
      "the laptop was really good and it goes really fast just the way i thought it would run.\n",
      "i would really recommend it to any person out there to get this laptop because its really worth it.\n",
      "And its really cheap and you wont regret buying it.\n"
     ]
    }
   ],
   "source": [
    "for item in original_results:\n",
    "    print(item['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n",
      "DEBUG:security.authorization:Running authorization for token for functionality Analysis/Aspect-Sentiments and language None\n"
     ]
    }
   ],
   "source": [
    "modified_results = []\n",
    "\n",
    "for package in sentence_packages:\n",
    "    modified_result_pp = []\n",
    "    for item in package['modified_sentences']:\n",
    "        # print(item)\n",
    "        modified_sentence = item[1]\n",
    "        modified_word = item[0]\n",
    "        \n",
    "        \n",
    "        modified_result_set = pred.predict([{'text': modified_sentence, 'segments': [{'span':[0,0],'text': modified_sentence}]}], key, with_segments=True)\n",
    "    \n",
    "        if modified_result_set[0]:\n",
    "            modified_result = modified_result_set[0][0]\n",
    "            #modified_aspect = modified_result['aspect']\n",
    "            #modified_sentiment = modified_result['sentiment']\n",
    "        \n",
    "        else:\n",
    "            print(modified_result_set)\n",
    "            package['modified_sentences'].remove(item)\n",
    "            print(package)\n",
    "        \n",
    "        \n",
    "        modified_result_pp.append(modified_result_set)\n",
    "    modified_results.append(modified_result_pp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_results\n",
    "ich auch mit den Nerven huhuhuu \n",
    "haha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    important_words = []\n",
    "    modified_sentences_filtered = []\n",
    "    \n",
    "    for item in package['modified_sentences']:\n",
    "        modified_sentence = item[1]\n",
    "        modified_word = item[0]\n",
    "        \n",
    "        modified_result = pred.predict([modified_sentence], key)[0][0];\n",
    "        modified_aspect = modified_result['aspect']\n",
    "        modified_sentiment = modified_result['sentiment']\n",
    "        \n",
    "        \n",
    "        if modified_aspect != original_aspect or modified_sentiment != original_sentiment:\n",
    "            important_words.append(modified_word)\n",
    "            modified_sentences.append(modified_sentence)\n",
    "            print('original sentence :', original_sentence, 'original prediction: ', original_result, 'modified prediction: ', modified_result)\n",
    "        print(\"important words: \", important_words)\n",
    "    \n",
    "    important_words_list_unfiltered.append(important_words)\n",
    "    modified_sentences_filtered.append(modified_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_words_list_unfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_sentences_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a new important words list and a new sentence package list\n",
    "### Onyl those packages, where there was a modification possible through the LOO method should be worked on\n",
    "\n",
    "#### only those modified sentences, where there was a change possible should be in the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_words_list = []\n",
    "test_packages = []\n",
    "for e, item in enumerate(important_words_list_unfiltered):\n",
    "    if item:\n",
    "        important_words_list.append(item)\n",
    "        test_packages.append(sentece_packages_unfiltered[e])\n",
    "        \n",
    "print(len(important_words_list))\n",
    "print(len(test_packages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_packages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, package in enumerate(test_packages):\n",
    "    important_word = important_words_list[e]\n",
    "    modified_sentences = package['modified_sentences']\n",
    "    for item in modified_sentences:\n",
    "        print(item)\n",
    "        #if impo\n",
    "    #print(important_words)\n",
    "    #print(modified_sentences)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store important_words_list\n",
    "%store sentence_packages\n",
    "%store original_results\n",
    "\n",
    "#for dev\n",
    "%store test_packeges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
